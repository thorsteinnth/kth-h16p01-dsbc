Group membership service
Atomic multicast

Nodes with leader
Send message to leader - leader does basic multicast to all - if leader dies elect new one

Node join - send request to any node - leader decides when to include it and send a new view of system to all nodes

Application layer has a group process that communication goes through - no views go to the application layer

View synchrony
"messages are delivered in a view"
For all messages in a view we guarantee:
- FIFO - in the order they were sent by the sending node
- Total order - all nodes see the same sequence
- Reliable - If a correct node delivers a message all correct nodes deliver the message

Correct node:
Does not fail during a view, i.e. it survives to install the next view
(a node will fail only by crashing and will then never be heard from again)

NOTE:
Not guaranteed that a send message is delivered. Async sending and no ACKs.
If failing leader then a sent message might disappear.

Leader:
Node is either leader or slave
One leader (hopefully)
All slaves forward messages to leader, leader tags it with seqnum, multicast it to all other nodes
Leader can also accept messages from its own master - the application layer
NOTE: Application layer does not know if its group is a leader or a slave

Slave:
Receive messages from application layer and forward them to the leader.
Receive messages from leader and forward them to the application layer.
Have to be able to deal with it if the leader fails.

Election:
All slaves have same list of peers.
First node in the list is the leader.
If I am the leader I resend the last message I received.
Slaves monitor the new leader.

Application layer:
Create a group process
Contact any other application layer process it knows of
- Request to join the group, send the PID of its own group process
- Wait for view delivery, containing the peer processes in the group
No guarantee that the join request makes it - the leader might be dead, or the request might not be delivered to the
leader
- application layer process just timeouts and aborts the attempt
After joining, must get current state of group (color)
Sends request to obtain state to atomic multicast layer, and waits to receive the message from itself
- now I know that the other processes see this message and respond by sending the state, also using the multicast layer
NOTE:
state message might not be the first message we receive
state change messages might be in the pipeline
after receiving the state message these state change messages must be applied before the process is up and running
simply let any state change messages remain in the queue an choose to handle state message first, before
state change messages (using erlang's implicit deferral)

-----------------------------------------------------------------------------------------------------------------------

TODO:
One thing that we have to pay attention to is what we should do if, as a slave,
receive the view message from the new leader before we have noticed that the old leader is dead.
Should we refuse to handle view messages unless we have seen the Down message from the leader or should we happily
receive accept the new view and then ignore trailing Down messages.
- Right now we just monitor a new leader when we get the Down message

gms1 testing:
After killing leader they just stop changing colors. They try to multicast a color change, do that by sending a message
to the leader, but the leader is dead. So that message never goes anywhere.

gms2 testing:
After killing the leader, the next node becomes the leader. The remaining nodes keep changing colors, and stay
in sync.

-----------------------------------------------------------------------------------------------------------------------

missing messages testing:
leader crashes before he can broadcast the message to all workers.
introduced random crash. Am supposed to get the state of the workers out of sync.
What is happening?
Am getting them out of sync. Got that by having 4 workers.

NOPE.
Something to do with the fact that they are just starting to monitor a new leader when they get the Down message.
Don't actually start monitoring a new leader when they get the view message?
NOPE.

Þeir eru sammála um hver er leaderinn, samt er þetta að gerast.

7> test:test_gms2_random_crash().
Will kill all processes in 90 sec
leader 1: crash
[4][<0.141.0>] LEADER IS: <0.139.0>
[5][<0.142.0>] LEADER IS: <0.139.0>
[3][<0.140.0>] LEADER IS: <0.139.0>
[2][<0.139.0>] LEADER IS: myself
leader 2: crash
[4][<0.141.0>] LEADER IS: <0.140.0>
[3][<0.140.0>] LEADER IS: myself
[5][<0.142.0>] LEADER IS: <0.140.0>
leader 3: crash
[5][<0.142.0>] LEADER IS: <0.141.0>
[4][<0.141.0>] LEADER IS: myself
leader 4: crash
[5][<0.142.0>] LEADER IS: myself
stop

-------------------------------

Ef leaderinn er að senda út á alla slaves, en deyr svo áður en hann nær að senda á alla (MISSING MESSAGES),
þá fá ekki allir skilaboðin um litabreytinguna. ATH að litabreytingin byggir alltaf á núverandi lit ((R+N) rem 256),
þannig að þeir syncast ekki saman þótt þeir verði svo sammála um nýja leaderinn.

Node1: 100
Node2: 100

Node1: 100
Node2: 100+10

Node1: 100+50 = 150
Node2: 110+50 = 160

Node1: 150+30 = 180
Node2: 160+30 = 190

Sama þótt þeir séu núna í synci með öll skilaboð sem þeir fá úr þessu, þá er Node2 alltaf með 10 hærra R gildi
-> Alltaf mismunandi litir.

--------------------------------

[3][<0.196.0>] LEADER SENT MESSAGE TO NODE: <0.197.0>, MESSAGE: {msg,
                                                                 {change,6}}
[3][<0.196.0>] LEADER SENT MESSAGE TO NODE: <0.198.0>, MESSAGE: {msg,
                                                                 {change,6}}
[3][<0.196.0>] LEADER SENT MESSAGE TO NODE: <0.197.0>, MESSAGE: {msg,
                                                                 {change,7}}
[3][<0.196.0>] LEADER SENT MESSAGE TO NODE: <0.198.0>, MESSAGE: {msg,
                                                                 {change,7}}
[3][<0.196.0>] LEADER SENT MESSAGE TO NODE: <0.197.0>, MESSAGE: {msg,
                                                                 {change,20}}

!!!CRASH BEFORE IT CAN SEND THE MESSAGE TO 198!!!

leader 3: crash
[5][<0.198.0>] LEADER IS: <0.197.0>
[4][<0.197.0>] LEADER SENT MESSAGE TO NODE: <0.198.0>, MESSAGE: {view,
                                                                 [<0.197.0>,
                                                                  <0.198.0>],
                                                                 [<0.191.0>,
                                                                  <0.192.0>]}
[4][<0.197.0>] LEADER IS: myself
[4][<0.197.0>] LEADER SENT MESSAGE TO NODE: <0.198.0>, MESSAGE: {msg,
                                                                 {change,14}}
[4][<0.197.0>] LEADER SENT MESSAGE TO NODE: <0.198.0>, MESSAGE: {msg,
                                                                 {change,10}}
[4][<0.197.0>] LEADER SENT MESSAGE TO NODE: <0.198.0>, MESSAGE: {msg,
                                                                 {change,10}}

Node 198 is now missing the {change,20} message, so it will be out of sync with the color progression of node 197
(the leader).

-----------------------------------------------------------------------------------------------------------------------

Reliable multicast to fix the missing messages problem.

Vanilla reliable multicaster (process that forwards all messages before delivering them to a higher layer) would be
expensive.

Keep copy of last message from leader.
If we detect the death of the leader then some nodes may never have gotten this message (if he was in the middle
of the basic multicast procedure).
Assume:
- Messages are reliably delivered
-> if leader sends message to A and then B, if B receives the message, then also A will receive it (the leader can't have
died before sending to A, it must have been able to send there since it was able to send to B, note that the only way we
lose messages is if the leader dies, because of the reliable delivery condition)

Leader is sending messages out in the order that the slaves are in in the list of peers.
So, if anyone receives a message before the leader crashes while multicasting, it is guaranteed that the next
leader has received the message (he is the first node in the list of peers).
(either him and no one else, or him and an arbitrary number of other nodes).
-> only the next leader needs to resend the message

This way a node can receive duplicate messages
New leader + node X received message before the leader dying
New leader resends message to all nodes
Node X receives a duplicate
-> Number all messages and only deliver new messages to the application layer

Note that if the leader dies before it has the chance to send out any messages, we do not have a problem.
A new leader will be elected and the nodes will not go out of sync, since none of them received the change color
(increment color actually) message.

Not getting them in sync

[4][<0.78.0>] RECEIVED MESSAGE: {msg,53,{change,1}}
[5][<0.79.0>] RECEIVED MESSAGE: {msg,53,{change,1}}
[6][<0.80.0>] RECEIVED MESSAGE: {msg,53,{change,1}}
leader 3: crash
[4][<0.78.0>] RECEIVED MESSAGE: {msg,54,{change,5}}
[5][<0.79.0>] RECEIVED MESSAGE: {msg,54,{change,5}}
[6][<0.80.0>] RECEIVED MESSAGE: {msg,54,{change,5}}

!!!EVERYBODY AT 54

[4][<0.78.0>] LEADER IS: myself
[5][<0.79.0>] LEADER IS: <0.78.0>
[6][<0.80.0>] LEADER IS: <0.78.0>

!!!RESENDING 54

[4][<0.78.0>] NEW LEADER BROADCASTING LAST RECEIVED MSG: {msg,54,{change,5}}
[5][<0.79.0>] RECEIVED MESSAGE: {msg,54,{change,5}}
[6][<0.80.0>] RECEIVED MESSAGE: {msg,54,{change,5}}

!!! THE OTHER NODES WILL PERFORM THIS COLOR CHANGE! THE CRITERIA IS IF I<N
!!! NOW THE TWO SLAVES ARE AHEAD OF THE LEADER IN THE COLOR PROGRESSION

[5][<0.79.0>] RECEIVED MESSAGE: {view,55,
                                      [<0.78.0>,<0.79.0>,<0.80.0>],
                                      [<0.72.0>,<0.73.0>,<0.74.0>]}
[6][<0.80.0>] RECEIVED MESSAGE: {view,55,
                                      [<0.78.0>,<0.79.0>,<0.80.0>],
                                      [<0.72.0>,<0.73.0>,<0.74.0>]}
[5][<0.79.0>] RECEIVED MESSAGE: {msg,56,{change,2}}
[6][<0.80.0>] RECEIVED MESSAGE: {msg,56,{change,2}}
[5][<0.79.0>] RECEIVED MESSAGE: {msg,57,{change,11}}
[6][<0.80.0>] RECEIVED MESSAGE: {msg,57,{change,11}}

NOTE
ERROR IN ASSIGNMENT DOC
we discard messages when I <= N, where I is the incoming seqnum, and N is our seqnum (i.e. the seqnum of the last
message we accepted).
The assignment doc has I < N.

4][<0.122.0>] RECEIVED MESSAGE: {msg,52,{change,15}}
[5][<0.123.0>] RECEIVED MESSAGE: {msg,52,{change,15}}
[6][<0.124.0>] RECEIVED MESSAGE: {msg,52,{change,15}}
[4][<0.122.0>] RECEIVED MESSAGE: {msg,53,{change,5}}
[5][<0.123.0>] RECEIVED MESSAGE: {msg,53,{change,5}}
[6][<0.124.0>] RECEIVED MESSAGE: {msg,53,{change,5}}
leader 3: crash
[4][<0.122.0>] RECEIVED MESSAGE: {msg,54,{change,17}}
[5][<0.123.0>] RECEIVED MESSAGE: {msg,54,{change,17}}
[6][<0.124.0>] RECEIVED MESSAGE: {msg,54,{change,17}}
[4][<0.122.0>] LEADER IS: myself
[5][<0.123.0>] LEADER IS: <0.122.0>
[6][<0.124.0>] LEADER IS: <0.122.0>
[4][<0.122.0>] NEW LEADER BROADCASTING LAST RECEIVED MSG: {msg,54,{change,17}}
[5][<0.123.0>] DISCARDING MESSAGE WITH SEQNUM: 54, CURRENT SEQNUM: 54, MESSAGE: {change,
                                                                                 17}
[6][<0.124.0>] DISCARDING MESSAGE WITH SEQNUM: 54, CURRENT SEQNUM: 54, MESSAGE: {change,
                                                                                 17}
[5][<0.123.0>] RECEIVED MESSAGE: {view,55,
                                     [<0.122.0>,<0.123.0>,<0.124.0>],
                                     [<0.115.0>,<0.116.0>,<0.117.0>]}
[6][<0.124.0>] RECEIVED MESSAGE: {view,55,
                                     [<0.122.0>,<0.123.0>,<0.124.0>],
                                     [<0.115.0>,<0.116.0>,<0.117.0>]}
[5][<0.123.0>] RECEIVED MESSAGE: {msg,56,{change,7}}
[6][<0.124.0>] RECEIVED MESSAGE: {msg,56,{change,7}}
[5][<0.123.0>] RECEIVED MESSAGE: {msg,57,{change,1}}
[6][<0.124.0>] RECEIVED MESSAGE: {msg,57,{change,1}}
[5][<0.123.0>] RECEIVED MESSAGE: {msg,58,{change,2}}
[6][<0.124.0>] RECEIVED MESSAGE: {msg,58,{change,2}}

OK NOW.

-----------------------------------------------------------------------------------------------------------------------

Run some experiments and create a group spanning several computers, if available.
Can we keep a group rolling by adding more nodes as existing nodes die?

Yes I can. Just testing on one computer though.
Have to have a reference to a node that is alive.
Best to test this by putting the arghh value to 200 so they don't crash to often.
Can then do e.g.
W6 = test:add(6, gms3, W5, 1000)
Where W5 has to be alive, to add it to the group.

-----------------------------------------------------------------------------------------------------------------------

4 Optional task for extra bonus: What could possible go wrong

Note that the Erlang system's only guarantee is that messages are delivered in FIFO order, not that they actually
do arrive.
We have built our system relying on reliable delivery of messages, something that is not guaranteed.

How would we have to change the implementation to handle the possibly lost messages?
How would this impact performance?

For the extra bonus, change your implementation to handle the possibly lost messages.
In the report, shortly explain your changes and discuss how this would impact performance.

We also rely on that the Erlang failure detector is perfect.

The second reason why things will not work is that we rely on that the Erlang failure detector is perfect
i.e. that it will never suspect any correct node for having crashed.
Is this really the case?
Can we adapt the system so that it will behave correctly if it does make progress,
even though it might not always make progress?

The third reason why things do not work is that we could have a situation where one incorrect node
delivers a message that will not be delivered by any correct node.
This could happen even if we had reliable send operations and perfect failure detectors.
How could this happen and how likely is it that it does? What would a solution look like?

-----------------------------------------------------------------------------------------------------------------------

For the extra bonus, change your implementation to handle the possibly lost messages.
In the report, shortly explain your changes and discuss how this would impact performance.
- geri ráð fyrir að þetta sé nóg til að fá extra bonus. segir reyndar á heimasíðu verkefnisins að
"Specifically for this homework, be prepared to discuss the questions under section 4 at the reporting seminar."
En held að ég þurfi að vera búinn að finna svar við þeim til að fá bónusinn.

Handle lost messages:
Sent but not received.
Vera bara með eitthvað ACK og retries.
Þarf þá að monitora slaves? Vil ekki senda á dauðan slave og bíða að eilífu.

Queue sem heldur utan um sent but not acked messages
Þegar ég fæ ACK þá henda úr því queue.
Þegar slave deyr þá henda færslunum hans úr queueinu.

What if the ACKs get lost?
What if the leader dies, and his outgoingQueue gets lost as well?

Er ekki að fá ACK fyrir fyrstu tvö msgs

[1][<0.72.0>] LEADER BROADCASTING VIEW MESSAGE WITH SEQNUM: 0
[1][<0.72.0>] BCAST NEW OUTGOING QUEUE: [{<0.73.0>,0}]
[1][<0.72.0>] LEADER BROADCASTING VIEW MESSAGE WITH SEQNUM: 1
[1][<0.72.0>] BCAST NEW OUTGOING QUEUE: [{<0.73.0>,0},
                                         {<0.73.0>,1},
                                         {<0.74.0>,1}]
[1][<0.72.0>] LEADER BROADCASTING MCAST MESSAGE WITH SEQNUM: 2
[1][<0.72.0>] BCAST NEW OUTGOING QUEUE: [{<0.73.0>,0},
                                         {<0.73.0>,1},
                                         {<0.74.0>,1},
                                         {<0.73.0>,2},
                                         {<0.74.0>,2}]
[1][<0.72.0>] LEADER RECEIVING ACK FROM <0.73.0> FOR SEQNUM 1
[1][<0.72.0>] LEADER BROADCASTING MCAST MESSAGE WITH SEQNUM: 3
[1][<0.72.0>] BCAST NEW OUTGOING QUEUE: [{<0.73.0>,0},
                                         {<0.74.0>,1},
                                         {<0.73.0>,2},
                                         {<0.74.0>,2},
                                         {<0.73.0>,3},
                                         {<0.74.0>,3}]
.......

1][<0.72.0>] BCAST NEW OUTGOING QUEUE: [{<0.73.0>,0},
                                         {<0.74.0>,1},
                                         {<0.73.0>,21},
                                         {<0.74.0>,21},
                                         {<0.73.0>,22},

NOPE
Þetta er vegna þess að ég er ekki búinn að vinna úr view message-inu þegar ég sendi ACK to leader ... veit ekki
hver leaderinn er í fyrsta skiptið
NOPE
Var ekki að ACKa fysta view messageið sem kemur í init

-----------------------------------------------------------------------------------------------------------------------

Hvenær á ég að re-senda úr queueinu?
Ég verð að vera með þessa queue pælingu því ég get ekki látið hann bíða strax eftir ACKinu eftir að hafa sent.
Þá hunsar hann önnur join messages frá öðrum á meðan, fá ekki response.
Hefði kannski getað bara látið lengra timeout samt.

Það meikar svosem sense að senda aftur úr outgoing queuinu áður en ég reyni að senda næstu skilaboð.
Þá tryggir það að FIFO orderið haldi sér.
Sendi ekki nýtt af stað fyrr en queueið er tómt!

Missing:
We should not send the next message until the OutgoingQueue is empty.
Now we can be out of sync for a bit.
We should also monitor the slaves for crashes. If a slave crashes, all his entries in the OutgoingQueue should
be removed.













