Notes from Chord paper

------------------------------------------------------------------

Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications

------------------------------------------------------------------

Abstract

Distributed lookup protocol - locate node with a particular data item

find node that contains key

Logarithmically scalable with number of Chord nodes

------------------------------------------------------------------

1 Introduction

P2P

Lookup in dynamic P2P systems with frequent node arrivals and departures

Mappa key á einhverja nóðu, valueið sem er geymt á nóðunni getur t.d.
verið data item eða eitthvað annað

Variant of consistent hashing
Gott load balancing, little movement of keys on joins/departures

Routing table í staðinn fyrir að vita um flestar aðrar nodes í kerfinu

N node system, geyma info um log(N) aðrar nodes í routing tables
Þarf þetta mikið fyrir efficient routing, en performance degrades gracefully
ef þetta info er outdated eða ekki til (svona mikið)
Þarf bara one piece of information til að virka (en slow)
Resolves lookups via O(logN) messages

Joins/departures oftast þarf max O(log_2(N)) messages til að laga system

"Routing a key through O(logN) other nodes to a destination"

------------------------------------------------------------------

2 Related work

Munur á chord og DNS osfrv
blabla

------------------------------------------------------------------

3 System model

Load balance
Decentralization
Scalability
Availability
Flexible naming

library

lookup(key) -> address of node with key

library also notifies application of changes to the set of keys
that that node is responsible for
-> get þá látið application færa data frá sér ef það á að færast á einhverja
nýja nóðu

App þarf að sjá um authentication, caching, replication, user friendly naming of
data

Use cases
- Cooperative mirroring
- Time shared storage
- Distributed indexes
- Large scale combinatorial search

------------------------------------------------------------------

4 The base chord protocol

Base: Simplified version that does not handle concurrent joins/departures

Fast distributed computation of a hash function mapping keys to nodes

Consistent hashing
High probability of balanced load
Líka high probability að þegar Nth node joins/leaves, only a O(1/N) fraction
of keys are moved to a different location

Improves scalability of consistent hashing by avoiding that every node
knows about every other node

To resolve hash function only need to communicate with O(logN) other nodes
(þannig þarf bara O(logN) messages, and only keeps info about those nodes

Join/departure þarf O(log_2(N)) messages til að updatea routing info

------------------------------------------------------------------

4.2 Consistent hashing

Each node and key get an m-bit identifier
hashed with a base hashing function like SHA-1
Hash nodes IP address -> node identifier
Hash key -> key identifier

m þarf að vera nógu stórt til að probability of two nodes or keys
hashing to the same identifier is negligible

Key identifiers are are ordered in a identifier circle, modulo 2^m

Key k is assigned to the first node whose identifier is equal to or or follows
(the identifier of) k in the identifier space.
-> called the successor node of key k
-> successor(k)
If identifiers are represented as a circle of numbers from 0 to 2^m-1, then
successor(k) is the first node clockwise from k

Fara til hægri í hringnum þangað til ég finn nóðu

Þegar node joinar network tekur hún eitthvað af keys frá successor nóðunni sinni
Þegar node leaves network, tekur successor nóðan hennar við öllum keys frá henni

Notar SHA-1 sem base hashing function

Venjulega consistent hashing notar virtual nodes á physical nodes til að reduce-a
load imbalance
Chord notar það ekki - load on a node can may exceed the average by at most
O(logN) factor with high probability (or based on standard hardness assumptions)

------------------------------------------------------------------

4.3 Scalable key location

Þarf í raun bara að vita af my successor node on the circle. Getur þá
routað í gegnum allan hringinn -> slow and inefficient samt
Gæti þurft að fara í gegnum allar N nóðurnar
-> Finger tables (routing tables)

Finger table:

At most m entries (where m is the number of bits in the identifier)
i-th entry in a table at node n contains the identity of the first node, s,
that succeeds n by at least 2^(i-1) on the identifier circle
s = successor(n+2^(i-1)), where 1 <= i <= m (and all arithmetic is modulo 2^m)

node s er þá i-th finger of node n, skrifað
n.finger[i].node

Finger table er með bæði Chord identifier og IP addressu og port number of
the relevant node ... get routað beint til hennar
NOTE: first finger of n is its immediate successor on the ring

For node 1 (m = 3):
(1+2^0) mod 2^3 = 2
(1+2^1) mod 2^3 = 3
(1+2^2) mod 2^3 = 5

Important characteristics:
1. Bara geyma info um fáar nodes, og veit meira um nodes closely following
heldur en langt í burtu
2. Finger table inniheldur generally ekki nóg info til að finna successor
of an arbitrary key k

node n að leita að node sem er með key k:
n leitar í finger tableinu sínu að node j whose ID most immediately precedes k,
and asks j for the node it knows whose ID is closest to k.
By repeating this process, n learns about nodes with IDs closer and closer to k.

Number of nodes that must be contacted to find a successor in an N-node network
is O(logN).
Average lookup time is (1/2)logN

------------------------------------------------------------------

4.4 Node joins

Mesta challengið er að preserve ability to locate every key in the network.
Two invariants þarf til að gera það:

1. Each node's successor is correctly maintained
2. For every key k, node successor(k) is responsible for k

With high probability, any node joining or leaving an N node Chord network will
use O(log^2(N)) messages to re-establish the Chord routing invariants and finger
tables.

Hver nóða er með predecessor pointer.
Chord identifier og IP addressa á immediate predecessor of that node, can be used
to walk counter clockwise around the identifier circle.

Node n joins, þarf að gera:
1. Initialize the predecessor and fingers of node n
2. Update the fingers and predecessors of existing nodes to reflect the addition
of n
3. Notify the higher level software so that it can transfer state (e.g. values)
associated with the keys that n is now responsible for

Node n fréttir af node n' sem er nú þegar í Chord networkinu
Node n notar n' til að initialize-a its state and add itself to the Chord network

Initialize fingers and predecessor:
Biðja n' um að looka þeim upp
... tæknilegt stuff
Node n sem er að joina getur líka beðið immediate neighbor um copy af finger
table-inu hans og predecessor. n getur þá notað þessar töflur til að hjálpa
sér að fylla út í sínar eigin töflur.
Tími til að fylla finger table er O(logN)

Updating fingers of existing nodes:
Þarf að setja node n í töflurnar hjá existing nodes
Tæknilegt + pseudocode
Number of nodes that need to be updated is O(logN).
Það tekur O(log^2(N)) að finna og update-a þessar nodes.

Transferring keys:
Þarf að færa responsibility á keys sem n á að sjá um yfir á n (that n is now
successor of).
Node n getur orðið successor for keys that were previously the responsibility of
the node immediately following n, so n only needs to contact that one node to
transfer responsibility for all relevant keys.

------------------------------------------------------------------

5 Concurrent operations and failures

Þarf að deala við nodes joining the system concurrently and with nodes that
fail or leave voluntarily.

------------------------------------------------------------------

5.1 Stabilization

Erfitt að halda invariants réttum ef margar concurrent joins.
Stabilization protocol er used tol að keep nodes' successor pointers
up to date, which is sufficient to guarantee correctness of lookups.
Þessir successor pointers eru svo notaðir til að verify and correct
finger table entries, sem gefur okkur hraða líka (ofan á að vera correct).

Ef að lookup gerist áður en stabilization er búið getur eitt af þrennu gerst:
1. Common case, finger tables involved in lookup are reasonably current og
lookup finnur réttan successor í O(logN) steps.
2. Successor pointers are correct, but fingers are not. This gives correct lookups
but they may be slower.
3. Nodes in the affected region have incorrect successor pointers, or keys may not
have yet migrated to newly joined nodes, and the lookup may fail.
Higher level software retries after a pause. Stabilization vinnur hratt og
ætti að laga pointers á meðan pause er í gangi.

Stabilization guarantees to add nodes to a Chord ring in a way that preserves
reachability of existing nodes, even in the face of concurrent joins and lost and
reordered messages.
Stabilization getur samt ekki lagað Chort system sem er búið að splittast í
marga disjoint cycles, eða single cycle sem loops multiple times around
the identifier space.

Maður notar þá stabilization í staðinn fyrir venjulega join mechanismann
Sjá pseudocode

stabilization procedure keyrt periodically.
Basically spurja successor hver predecessorinn hans er, ef það er ég ekki ég,
þá verður þessi predecessor successorinn minn
Þetta segir líka successornum frá mér, og þá getur successorinn merkt mig sem
predecessorinn hans

Priority er að successors séu réttir, fæ þá alltaf rétt lookups. Svo þegar
fix_fingers keyrt þá verður þetta aftur hratt.

Joins don't substantially damage the performance of fingers. Jumpin virka ennþá
og svo verður það bara linear scan í gegnum nýju nóðurnar if their fingers are not
yet accurate.
Unless a tremendous amount of nodes joins the system, the number of nodes between
two old nodes is likely to be very small, so the impact on lookup is negligible.

So long as the time it takes to adjust fingers is less than the time it takes the
network to double in size, lookups should continue to take O(logN) hops.

------------------------------------------------------------------

5.2 Failures and replication

Þegar node n fails, nodes sem innihalda n í finger tables-unum sínum,
þurfa að finna n's successor.
Failure of n also must not disrupt queries that are in progress as the system is
re-stabilizing.

Key step in failure recovery is maintaining correct successor pointers, queries
virka ennþá ef það er bara successor pointers (linear scan).

To achieve this each node maintains a successor list of its r nearest successors
on the Chord ring.
A modified operation of the stabilize routine maintains this list.

If node n notices that its successor has failed, it replaces it with the first live
entry in in its successor list.
Get þá sent ordinary lookups for keys for which the failed node was the successor to
the new successor. Stabilize mun svo laga finger table entries and successor list
entries pointing to the failed node.

After a node failure but before stabilization has completed, other nodes may attempt
to send requests through the failed node as part of a find_successor lookup.
Get þá notað alternate nodes, sem finna má í figner table entries preceding that
of the failed node. Ef failed node var með mjög lágt finger table index, nodes in
the successor list are also available as alterates.

Successor list getur líka hjálpað higher layer software að replicate-a data.
Implementationið gæti t.d. geymt replicas af data sem er tengt key at the k nodes
succeeding the key.
Node keeps track of r successors, og getur þess vegna sagt higher layer software
þegar successors come and go, og higher layer software getur þá propagate-að new
replicas as necessary.

------------------------------------------------------------------

6 Simulation and experimental results

Baj, bara lesa