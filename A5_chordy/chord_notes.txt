Notes from Chord paper

------------------------------------------------------------------

Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications

------------------------------------------------------------------

Abstract

Distributed lookup protocol - locate node with a particular data item

find node that contains key

Logarithmically scalable with number of Chord nodes

------------------------------------------------------------------

1 Introduction

P2P

Lookup in dynamic P2P systems with frequent node arrivals and departures

Mappa key á einhverja nóðu, valueið sem er geymt á nóðunni getur t.d.
verið data item eða eitthvað annað

Variant of consistent hashing
Gott load balancing, little movement of keys on joins/departures

Routing table í staðinn fyrir að vita um flestar aðrar nodes í kerfinu

N node system, geyma info um log(N) aðrar nodes í routing tables
Þarf þetta mikið fyrir efficient routing, en performance degrades gracefully
ef þetta info er outdated eða ekki til (svona mikið)
Þarf bara one piece of information til að virka (en slow)
Resolves lookups via O(logN) messages

Joins/departures oftast þarf max O(log_2(N)) messages til að laga system

"Routing a key through O(logN) other nodes to a destination"

------------------------------------------------------------------

2 Related work

Munur á chord og DNS osfrv
blabla

------------------------------------------------------------------

3 System model

Load balance
Decentralization
Scalability
Availability
Flexible naming

library

lookup(key) -> address of node with key

library also notifies application of changes to the set of keys
that that node is responsible for
-> get þá látið application færa data frá sér ef það á að færast á einhverja
nýja nóðu

App þarf að sjá um authentication, caching, replication, user friendly naming of
data

Use cases
- Cooperative mirroring
- Time shared storage
- Distributed indexes
- Large scale combinatorial search

------------------------------------------------------------------

4 The base chord protocol

Base: Simplified version that does not handle concurrent joins/departures

Fast distributed computation of a hash function mapping keys to nodes

Consistent hashing
High probability of balanced load
Líka high probability að þegar Nth node joins/leaves, only a O(1/N) fraction
of keys are moved to a different location

Improves scalability of consistent hashing by avoiding that every node
knows about every other node

To resolve hash function only need to communicate with O(logN) other nodes
(þannig þarf bara O(logN) messages, and only keeps info about those nodes

Join/departure þarf O(log_2(N)) messages til að updatea routing info

------------------------------------------------------------------

4.2 Consistent hashing

Each node and key get an m-bit identifier
hashed with a base hashing function like SHA-1
Hash nodes IP address -> node identifier
Hash key -> key identifier

m þarf að vera nógu stórt til að probability of two nodes or keys
hashing to the same identifier is negligible

Key identifiers are are ordered in a identifier circle, modulo 2^m

Key k is assigned to the first node whose identifier is equal to or or follows
(the identifier of) k in the identifier space.
-> called the successor node of key k
-> successor(k)
If identifiers are represented as a circle of numbers from 0 to 2^m-1, then
successor(k) is the first node clockwise from k

Fara til hægri í hringnum þangað til ég finn nóðu

Þegar node joinar network tekur hún eitthvað af keys frá successor nóðunni sinni
Þegar node leaves network, tekur successor nóðan hennar við öllum keys frá henni

Notar SHA-1 sem base hashing function

Venjulega consistent hashing notar virtual nodes á physical nodes til að reduce-a
load imbalance
Chord notar það ekki - load on a node can may exceed the average by at most
O(logN) factor with high probability (or based on standard hardness assumptions)

------------------------------------------------------------------

4.3 Scalable key location

Þarf í raun bara að vita af my successor node on the circle. Getur þá
routað í gegnum allan hringinn -> slow and inefficient samt
Gæti þurft að fara í gegnum allar N nóðurnar
-> Finger tables (routing tables)

Finger table:

At most m entries (where m is the number of bits in the identifier)
i-th entry in a table at node n contains the identity of the first node, s,
that succeeds n by at least 2^(i-1) on the identifier circle
s = successor(n+2^(i-1)), where 1 <= i <= m (and all arithmetic is modulo 2^m)

node s er þá i-th finger of node n, skrifað
n.finger[i].node

Finger table er með bæði Chord identifier og IP addressu og port number of
the relevant node ... get routað beint til hennar
NOTE: first finger of n is its immediate successor on the ring

For node 1 (m = 3):
(1+2^0) mod 2^3 = 2
(1+2^1) mod 2^3 = 3
(1+2^2) mod 2^3 = 5

Important characteristics:
1. Bara geyma info um fáar nodes, og veit meira um nodes closely following
heldur en langt í burtu
2. Finger table inniheldur generally ekki nóg info til að finna successor
of an arbitrary key k

node n að leita að node sem er með key k:
n leitar í finger tableinu sínu að node j whose ID most immediately precedes k,
and asks j for the node it knows whose ID is closest to k.
By repeating this process, n learns about nodes with IDs closer and closer to k.

Number of nodes that must be contacted to find a successor in an N-node network
is O(logN).
Average lookup time is (1/2)logN

------------------------------------------------------------------

4.4 Node joins











